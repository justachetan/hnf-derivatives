<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Polynomial-fitting based accurate differential operators for hybrid neural fields like Instant NGP">
  <meta name="keywords" content="Neural Fields, Derivatives, Instant NGP, hybrid neural fields">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Accurate Differential Operators for Hybrid Neural Fields</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    table {
        border-collapse: collapse;
        width: 100%;
    }

    th {
        text-align: left;
        padding: 8px;
        border-bottom-width: 0;
        background-color: #f2f2f2;
    }

    #table1 td {
      text-align: left;
      padding: 8px;
      border-bottom-width: 0;
    }

    #table2 td {
        text-align: left;
        padding: 8px;
        border-bottom-width: 0;
    }
    

    .bottom-border {
        border-bottom: 2px solid #dddddd;
    }
  </style>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Accurate Differential Operators for Hybrid Neural Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://justachetan.github.io">Aditya Chetan</a>,</span>
            <span class="author-block">
              <a href="https://www.guandaoyang.com">Guandao Yang</a>,</span>
            <span class="author-block">
              <a href="https://zichenwang01.github.io">Zichen Wang</a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.cornell.edu/~srm/">Steve Marschner</a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.cornell.edu/~bharathh/">Bharath Hariharan</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><img src="static/images/cornell_logo_simple_b31b1b.png" width="200"></span>
          </div>
          <div class="columns is-centered" style="margin-bottom: 0em">
              <div class="column is-max-desktop has-text-centered">
                  <h1 class="title is-4 publication-title" style="margin-bottom:0rem">
                      <strong>CVPR 2025</strong>
                  </h1>
              </div>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2312.05984.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2312.05984"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/justachetan/hnf-derivatives"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=54uuYC8xgoI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" width="100%">
      <div class="subtitle has-text-centered">
        Our approach can compute accurate derivatives (illustrated here by surface normals) from hybrid neural fields like <span class="dnerf">Instant NGP</span>, compared to Autodiff.
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Neural fields have become widely used in various fields, from shape representation to neural rendering, and for solving partial differential equations (PDEs). With the advent of hybrid neural field representations like <span class="dnerf">Instant NGP</span> that leverage small MLPs and explicit representations, these models train quickly and can fit large scenes. Yet in many applications like rendering and simulation, hybrid neural fields can cause noticeable and unreasonable artifacts. This is because they do not yield accurate spatial derivatives needed for these downstream applications.</p>
          <p>In this work, we propose two ways to circumvent these challenges. Our first approach is a post hoc operator that uses local polynomial-fitting to obtain more accurate derivatives from pre-trained hybrid neural fields. Additionally, we also propose a self-supervised fine-tuning approach that refines the neural field to yield accurate derivatives directly while preserving the initial signal. We show the application of our method on rendering, collision simulation, and solving PDEs. We observe that using our approach yields more accurate derivatives, reducing artifacts and leading to more accurate simulations in downstream applications.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Visual Effects. -->
    <div class="column">
      <div class="content">
        <h2 class="title is-3">High-frequency noise in hybrid neural fields</h2>
        <p>
          We observe that hybrid neural fields contain high-frequency noise in the learned signal. This noise can cause artifacts in derivatives computed using automatic differentiation. 
        </p>
        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="./static/images/fig2_iclr.png" width="52%">
              <img src="./static/images/fft_1d_slice.png" width="47%">
              <div class="subtitle has-text-centered">
                <b>(Left) Inaccurate differential operators of neural fields.</b> Hybrid neural SDF of a circle in 2D. <b>(Right) Fourier spectrum of a hybrid neural SDF.</b> Computed over a 1D slice (dashed line in left) of the SDF of a 2D circle.
              </div>
            </div>
          </div>
        </section>
        <p>These artifacts cause issues in downstream applications like rendering and solving PDEs with hybrid neural fields.</p>
        <h2 class="title is-3">Method</h2>
        <p>
          We propose two approaches to alleviate this problem: post hoc polynomial-fitting operators and a fine-tuning approach to improve the accuracy of autodiff derivatives.
        </p>
        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="./static/images/problem_setup.png" width="70%" style="display: block; margin-left: auto; margin-right:auto">
              <div class="subtitle has-text-centered">
                Given a pre-trained hybrid neural field with noisy autodiff derivatives, we propose two approaches for accurate derivatives. Our polynomial-fitting operator can be applied in a post hoc manner while our fine-tuning approach directly improves autodiff derivatives of the field.
              </div>
            </div>
          </div>
        </section>
        <h3 class="title is-4">Post hoc polynomial-fitting derivatives</h3>
        <p>Given a pre-trained hybrid neural field and a query point, we propose fitting a polynomial through the local neighborhood of the query point. We then compute autodiff derivatives of this fitted polynomial instead of the learned signal.</p>
        <h3 class="title is-4">Fine-tuning approach</h3>
        <p>Since our post hoc operators would require changes in the downstream pipelines. To prevent this, we also propose a fine-tuning approach that aligns the autodiff derivatives of hybrid neural fields with the smoothed derivatives from alternative sources like our post hoc operators or finite-difference stencils, while preserving the original 0<sup>th</sup> order signal. Our fine-tuning objective is independent of the type of smoothed derivative operator itself.</p>
        
        
        <h2 class="title is-3">Results</h2>
        <p>We evaluate our methods on hybrid neural SDFs of 3D shapes from the <span class="dnerf"><a href="https://www.cg.tuwien.ac.at/research/publications/2020/erler-2020-p2s/">FamousShape</a></span> dataset.  
          We experiment with tree type of hybrid neural fields: <span class="dnerf"><a href="https://nvlabs.github.io/instant-ngp/">Instant NGP</a></span>, Dense Grid, and <span class="dnerf"><a href="https://nvlabs.github.io/eg3d/">Tri-plane</a></span> (only post hoc analysis).
        Below, we show the evaluation results for <span class="dnerf">Instant NGP</span>. For detailed results, please refer to our paper.</p>
        
        <p>Our <b>post hoc operators</b> are able to provide more accurate derivatives than finite-difference or autodiff baselines, and perform on-par, if not better than Monte Carlo approaches like gaussian averaging of autodiff derivatives.</p>
        
        <table id="table1">
          <caption><strong>Table 1. Post Hoc Operator Evaluation for <span class="dnerf">Instant NGP</span></strong>: We compare our operators with baselines like autodiff (AD), finite-difference stencils (FD), stochastic finite-difference (SFD), and gaussian averaging of autodiff (GAD).</caption>
          <thead>
            <tr>
              <th rowspan="2">Method</th>
              <th colspan="4" style="text-align: center;">Surface Normal</th>
              <th rowspan="2">RRE &darr;</th>
            </tr>
            <tr>
              <th>L2 &darr;</th>
              <th>Ang &darr;</th>
              <th>AA@1 &uarr;</th>
              <th>AA@2 &uarr;</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>AD</td>
              <td>0.21</td>
              <td>12.40</td>
              <td>1.58</td>
              <td>6.12</td>
              <td>-</td>
            </tr>
            <tr>
              <td>FD</td>
              <td>0.07</td>
              <td>4.20</td>
              <td>26.86</td>
              <td>55.22</td>
              <td>3.67</td>
            </tr>
            <tr>
              <td>GAD</td>
              <td>0.05</td>
              <td>2.99</td>
              <td>38.35</td>
              <td>66.86</td>
              <td>-</td>
            </tr>
            <tr>
              <td>SFD</td>
              <td>0.95</td>
              <td>57.67</td>
              <td>0.01</td>
              <td>0.07</td>
              <td>-</td>
            </tr>
            <tr>
              <td>Ours</td>
              <td><strong>0.05</strong></td>
              <td><strong>2.80</strong></td>
              <td><strong>42.92</strong></td>
              <td><strong>67.90</strong></td>
              <td><strong>0.89</strong></td>
            </tr>
          </tbody>
        </table>

        <p>Our <b>fine-tuning</b> approach also yields more accurate autodiff operators than directly applying autodiff, while preserving the fidelity of the original neural field. 
          Our approach also performs better than traditional regularization approaches like Eikonal regularization that were proposed to encourage smoother iso-surfaces in neural fields.</p>

        <table id="table2">
          <caption><strong>Table 2. Fine-tuning / <mark style="background-color: #fff2cc;">Regularization</mark> Comparison for <span class="dnerf">Instant NGP</span></strong>  Our fine-tuning approach improves the accuracy of surface normals obtained from automatic differentiation. We compare autodiff operators before (first row) and after fine-tuning.</caption>
          <thead>
            <tr>
              <th rowspan="2">Method</th>
              <th colspan="4" style="text-align: center;">Surface Normal</th>
              <th colspan="2" style="text-align: center;">Mesh Reconstruction</th>
            </tr>
            <tr>
              <th>L2 &darr;</th>
              <th>Ang &darr;</th>
              <th>AA@1 &uarr;</th>
              <th>AA@2 &uarr;</th>
              <th>Chamfer Distance &darr;</th>
              <th>F-Score &uarr;</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>-</td>
              <td>0.21</td>
              <td>12.40</td>
              <td>1.58</td>
              <td>6.12</td>
              <td>9.24 &times; 10<sup>-4</sup></td>
              <td>93.07</td>
            </tr>
            <tr style="background-color: #fff2cc;">
              <td>Eikonal</td>
              <td>0.11</td>
              <td>6.51</td>
              <td>12.24</td>
              <td>31.48</td>
              <td>9.23 &times; 10<sup>-4</sup></td>
              <td>92.90</td>
            </tr>
            <tr style="background-color: #fff2cc;">
              <td>FD-Eikonal</td>
              <td>0.10</td>
              <td>6.17</td>
              <td>13.71</td>
              <td>33.27</td>
              <td>9.25 &times; 10<sup>-4</sup></td>
              <td>89.85</td>
            </tr>
            <tr>
              <td>FD</td>
              <td>0.08</td>
              <td>5.14</td>
              <td>21.16</td>
              <td>46.63</td>
              <td>9.35 &times; 10<sup>-4</sup></td>
              <td>90.24</td>
            </tr>
            <tr>
              <td>Ours</td>
              <td><strong>0.05</strong></td>
              <td><strong>3.19</strong></td>
              <td><strong>33.60</strong></td>
              <td><strong>60.24</strong></td>
              <td>9.28 &times; 10<sup>-4</sup></td>
              <td>92.28</td>
            </tr>
          </tbody>
        </table>
  

        
        <h2 class="title is-3">Applications</h2>
        <p>Our approaches also provide advantages in downstream applications of hybrid neural fields.</p>
        <h3 class="title is-4">Rendering</h3>
        <p>Rendering hybrid neural SDFs with our approaches yields results that are free from unnecessary artifacts that arise in the case of directly using of autodiff derivatives.</p>
        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="./static/images/rendering_iclr.png" width="100%">
              <div class="subtitle has-text-centered">
                <b>Accurate Normals for Rendering.</b> A perfectly specular sphere lighted by an environment map (top) and a diffuse Armadillo (inset) lit by a light source put in front of the object (bottom). In both cases, noisy normals from autodiff lead to artifacts in rendering as shown in the highlighted parts, that are mitigated by our approaches.
              </div>
            </div>
          </div>
        </section>
        <h3 class="title is-4">Collision simulation</h3>
        <p>Surface normals are required for accurate simulations when modeling collisions to compute trajectories. We consider the case of two spheres undergoing head-on collisions and simulate their trajectories post-collision. To obtain these trajectories, we use the normal estimates from the two SDFs at the analytical point of contact.</p>
        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="./static/images/coll_gt2.png" width="48%">
              <img src="./static/images/coll_autodiff2.png" width="48%">
              <div class="subtitle has-text-centered">
                <b>Effect of noisy normals on collision.</b> An illustration of the effect of noisy normals on collision. Two spheres undergoing perfectly elastic head-on collisions simulated using correct surface normals will re-trace their paths after a collision. Inaccurate normal estimates from autodiff yield incorrect trajectories after bouncing.
              </div>
            </div>
          </div>
        </section>
        <p>We model the collisions as perfectly elastic so that there is no loss of energy. In the ideal case, the spheres should rebound along the line joining the centers with the same velocity, but erroneous normal estimates will lead to incorrect trajectories.</p>
        <p>Averaged over 10<sup>6</sup> trials, the mean error obtained from our normals was <b>0.85&deg</b>, compared to <b>11.51&deg</b> for autodiff normals.</p>
        
        <h3 class="title is-4">Solving PDEs</h3>
        <section>
          <div class="columns is-centered">
            <div class="column">
              <p>We show that using our operators for solving a 2D advection equation using a hybrid neural field prevents the solution error from exploding. We solve an initial value problem with the gaussian pulse being advected with a constant velocity.</p>
              <p>We plot the mean squared error (MSE) for a finite difference grid solver, autodiff gradients (AD), and our polynomial-fitting approach. The error for AD explodes after the first few seconds and eventually crashes (indicated by &times;). Using the same hybrid neural field with our operator leads to more accurate solutions at all time steps.</p>
            </div>
            <div class="column">
              <img src="./static/images/pde_loss.png" width="100%">
              <!-- <div class="caption">
                <b>Effect of inaccurate gradients in PDE simulation</b>. Mean squared error (MSE) in a 2D advection simulation, for a finite difference grid solver, autodiff gradients (AD), and our polynomial-fitting approach. The error for AD explodes after the first few seconds and eventually crashes (indicated by &times;).
              </div> -->
            </div>
          </div>
        
      </div>
      
      
    </div>
    <!--/ Visual Effects. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{chetan2025accurate,
      title={Accurate Differential Operators for Hybrid Neural Fields}, 
      author={Aditya Chetan and Guandao Yang and Zichen Wang and Steve Marschner and Bharath Hariharan},
      year={2025},
      booktitle={CVPR},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/justachetan" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
<!--           <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p> -->
          <p>
            Website template taken from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
